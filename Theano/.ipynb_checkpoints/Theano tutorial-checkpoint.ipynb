{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Intro (10 min)\n",
    "  * What is Theano and why should I care?\n",
    "  * Installation\n",
    "  * Configuration\n",
    "* Basics (30 min)\n",
    "  * Baby steps\n",
    "  * Theano variables and functions\n",
    "  * Shared variables and more on functions\n",
    "  * Debugging\n",
    "* Theano for Machine Learning (50 min)\n",
    "  * Logistic regression\n",
    "  * SVM\n",
    "  * Kernels\n",
    "  * Regularization\n",
    "* Lasagne (?? min)\n",
    "  * MLP\n",
    "  * Convolutional neural network\n",
    "  * Goodies (?)\n",
    "\n",
    "\n",
    "The code is here: https://github.com/dudevil/datafest-theano-tutorial/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/probably_theano.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project was started back in 2007 at the University of Montreal\n",
    "\n",
    "Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. \n",
    "\n",
    "But it's also much more than that:\n",
    "\n",
    "* Language for symbolic computation\n",
    "* Optimizing compiler\n",
    "* Python library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Dependencies:\n",
    "     \n",
    "   * System: **g++, BLAS**\n",
    "   * Python: **NumPy, SciPy** \n",
    "   * Goodies: **CUDA, CuDNN**\n",
    "\n",
    "\n",
    "Current release:\n",
    "```\n",
    "pip install Theano\n",
    "```\n",
    "\n",
    "Bleeding-edge:\n",
    "```\n",
    "pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "```\n",
    "\n",
    "[Official instructions](http://deeplearning.net/software/theano/install.html#install)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~/.theanorc\n",
    "\n",
    "```\n",
    "    [global]\n",
    "    device = gpu # cpu\n",
    "    floatX = float32\n",
    "    optimizer_including=cudnn \n",
    "    allow_gc = False # быстрее но использует больше памяти\n",
    "    #exception_verbosity=high\n",
    "    #optimizer = None  # полезно при отладке\n",
    "    #profile = True\n",
    "    #profile_memory = True\n",
    "\n",
    "    [nvcc]\n",
    "    fastmath = True\n",
    "```\n",
    "\n",
    "[More on configuration](http://deeplearning.net/software/theano/library/config.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano has great documentation:\n",
    "   * http://deeplearning.net/software/theano/tutorial/\n",
    "   * http://deeplearning.net/software/theano/index.html#documentation\n",
    "   \n",
    "Code samples:\n",
    "   * http://deeplearning.net/tutorial/\n",
    "   \n",
    "And user community:\n",
    "   * https://groups.google.com/forum/#!forum/theano-users\n",
    "\n",
    "Don't be afraid to peek into the code:\n",
    "   * https://github.com/Theano/Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baby steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import theano \n",
    "import theano.tensor as T\n",
    "\n",
    "%pylab inline\n",
    "figsize(8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(121)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doing stuff with theano\n",
    "\n",
    "# declare theano variable\n",
    "a = T.lscalar() \n",
    "\n",
    "# construct an expression\n",
    "expression = 1 + 2 * a + a ** 2 \n",
    "\n",
    "# compile a theano function\n",
    "f = theano.function(\n",
    "    inputs=[a],        # input\n",
    "    outputs=expression  # output\n",
    ")\n",
    "\n",
    "# evaluate the expression\n",
    "f(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theano variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqkAAAH/CAYAAAB0GUSwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17404f5b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# only the declaration changes\n",
    "a = T.lvector()\n",
    "\n",
    "expression = 1 + 2 * a + a ** 2 \n",
    "\n",
    "f = theano.function(\n",
    "    inputs=[a],        # input\n",
    "    outputs=expression  # output\n",
    ")\n",
    "\n",
    "arg = arange(-10, 10)\n",
    "res = f(arg)\n",
    "\n",
    "plot(arg, res, c='m', linewidth=3.)\n",
    "grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  1.,  1.],\n",
       "       [ 1.,  3.,  1.],\n",
       "       [ 1.,  1.,  3.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can do the same with matrices\n",
    "x = T.dmatrix('x')\n",
    "y = T.dmatrix('y')\n",
    "\n",
    "z = x + 2 * y\n",
    "\n",
    "f = theano.function([x, y], z)\n",
    "f(ones((3, 3)), eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  2.,  2.,  2.],\n",
       "       [ 2.,  2.,  2.,  2.],\n",
       "       [ 2.,  2.,  2.,  2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# broadcasting also works\n",
    "x = T.dmatrix('x')\n",
    "v = T.dvector('v')\n",
    "\n",
    "z = v + x\n",
    "\n",
    "f = theano.function([x, v], z)\n",
    "f(ones((3, 4)), ones((4,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  2.  2.  2.]\n",
      " [ 2.  2.  2.  2.]\n",
      " [ 2.  2.  2.  2.]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('Bad input argument to theano function with name \"<ipython-input-6-96f108ecb7cc>:7\"  at index 0(0-based)', 'TensorType(float32, matrix) cannot store a value of dtype float64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to float32, or 2) set \"allow_input_downcast=True\" when calling \"function\".', array([[ 1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.]]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-96f108ecb7cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/fedor/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[1;32m    785\u001b[0m                             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fedor/anaconda2/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0;34m'\"function\".'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                             % (self, data.dtype, self.dtype))\n\u001b[0;32m--> 139\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m                 elif (allow_downcast is None and\n\u001b[1;32m    141\u001b[0m                         \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Bad input argument to theano function with name \"<ipython-input-6-96f108ecb7cc>:7\"  at index 0(0-based)', 'TensorType(float32, matrix) cannot store a value of dtype float64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to float32, or 2) set \"allow_input_downcast=True\" when calling \"function\".', array([[ 1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.]]))"
     ]
    }
   ],
   "source": [
    "# types should be handled with care\n",
    "x = T.fmatrix('x')\n",
    "v = T.fvector('v')\n",
    "\n",
    "z = v + x\n",
    "\n",
    "f = theano.function([x, v], z)\n",
    "print f(ones((3, 4), dtype=float32), np.ones((4,), dtype=float32))\n",
    "print f(ones((3, 4)), ones((4,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  2.  2.  2.]\n",
      " [ 2.  2.  2.  2.]\n",
      " [ 2.  2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# or you can supress the exception\n",
    "x = T.fmatrix('x')\n",
    "v = T.fvector('v')\n",
    "\n",
    "z = v + x\n",
    "\n",
    "f = theano.function(\n",
    "    inputs=[x, v],\n",
    "    outputs=z,\n",
    "    allow_input_downcast=True\n",
    ")\n",
    "print f(ones((3, 4), dtype=float64), ones((4,), dtype=float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared variables and more on functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# shared variables represent internal state\n",
    "state = theano.shared(0)\n",
    "\n",
    "i = T.iscalar('i')\n",
    "inc = theano.function([i],\n",
    "                      state,\n",
    "                      # updates the shared variable value\n",
    "                      updates=[(state, state+i)]) \n",
    "dec = theano.function([i],\n",
    "                      state,\n",
    "                      updates=[(state, state-i)])\n",
    "\n",
    "# more than one function can update the shared variable\n",
    "print state.get_value()\n",
    "inc(1)\n",
    "inc(1)\n",
    "inc(1)\n",
    "print state.get_value()\n",
    "dec(2)\n",
    "print state.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can also set the shared variable outside of the function\n",
    "state.set_value(-15)\n",
    "print state.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shared variables can in be inserted into the compurational graph\n",
    "x = T.lscalar('x')\n",
    "y = T.lscalar('y')\n",
    "i = T.lscalar('i')\n",
    "\n",
    "expression = (x - y) ** 2\n",
    "\n",
    "state = theano.shared(0)\n",
    "\n",
    "f = theano.function(\n",
    "    inputs=[x, i],\n",
    "    outputs=expression,\n",
    "    updates=[(state, state+i)],\n",
    "    # use the value at state as y\n",
    "    givens={\n",
    "        y : state\n",
    "    }\n",
    ")\n",
    "print f(5, 1) # (5 - 0) ^ 2 = 25\n",
    "print f(2, 1) # (2 - 1) ^ 2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can compute different outputs simultaneously\n",
    "x = T.lscalar('x')\n",
    "y = T.lscalar('y')\n",
    "\n",
    "square = T.square(x + y)\n",
    "sqrt = T.sqrt(x + y)\n",
    "\n",
    "f = theano.function(\n",
    "    inputs=[x, y],\n",
    "    outputs=[square, sqrt]\n",
    ")\n",
    "print f(5, 4)\n",
    "print f(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can compute different outputs simultaneously\n",
    "x = T.lscalar('x')\n",
    "y = T.lscalar('y')\n",
    "\n",
    "square = T.square(x + y)\n",
    "sqrt = T.sqrt(x + y)\n",
    "\n",
    "f = theano.function(\n",
    "    inputs=[x, y],\n",
    "    outputs=[square, sqrt]\n",
    ")\n",
    "# the sum get's computed only once\n",
    "theano.printing.debugprint(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a theano expression\n",
    "W = T.fmatrix('W')\n",
    "b = T.fvector('b')\n",
    "X = T.fmatrix('X')\n",
    "\n",
    "expr = T.dot(X, W) + b\n",
    "prob = 1 / (1 + T.exp(-expr))\n",
    "pred = prob > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and print it\n",
    "theano.pprint(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano.printing.debugprint(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano.printing.pydotprint(pred, outfile='pics/pred_graph.png', var_with_name_simple=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/pred_graph.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a theano expression\n",
    "W_1 = T.fmatrix('W_1')\n",
    "W_2 = T.fmatrix('W_2')\n",
    "b_1 = T.fvector('b_1')\n",
    "b_2 = T.fvector('b_2')\n",
    "activation = lambda expr: 1 / (1 + T.exp(-expr))\n",
    "X = T.fmatrix('X')\n",
    "y = T.ivector('y')\n",
    "\n",
    "d1 = T.dot(X, W_1) + b_1\n",
    "a1 = activation(d1)\n",
    "d2 = T.dot(a1, W_2) + b_2\n",
    "prob = activation(d2)\n",
    "loss = T.nnet.categorical_crossentropy(prob, y)\n",
    "\n",
    "theano.printing.pydotprint(loss, outfile='pics/pred_biggraph.png', var_with_name_simple=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/pred_biggraph.png\">\n",
    "<img src=\"pics/escalated_quickly.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on graph visualizations: http://deeplearning.net/software/theano/tutorial/printing_drawing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MonitorMode for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inspect_inputs(i, node, fn):\n",
    "    print i, node, \"input(s) value(s):\", [input[0] for input in fn.inputs],\n",
    "\n",
    "def inspect_outputs(i, node, fn):\n",
    "    print \"output(s) value(s):\", [output[0] for output in fn.outputs]\n",
    "\n",
    "x = theano.tensor.dscalar('x')\n",
    "f = theano.function(inputs=[x], \n",
    "                    outputs=(5 * x),\n",
    "                    mode=theano.compile.MonitorMode(\n",
    "                        pre_func=inspect_inputs,\n",
    "                        post_func=inspect_outputs))\n",
    "f(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More debugging technics are available here: http://deeplearning.net/software/theano/tutorial/debug_faq.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano for Machine learining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = linspace(-1, 1, 100)\n",
    "x2 = 1.5 - x1 ** 2 + random.normal(scale=0.2, size=100)\n",
    "x3 = random.normal(scale=0.4, size=100)\n",
    "x4 = random.normal(scale=0.4, size=100)\n",
    "\n",
    "permutation = random.permutation(np.arange(200))\n",
    "x = hstack((\n",
    "    vstack((x1, x2)),\n",
    "    vstack((x3, x4)))).T[permutation]\n",
    "y = concatenate((\n",
    "    zeros_like(x1),\n",
    "    ones_like(x3)))[permutation]\n",
    "\n",
    "# needed for pictures later\n",
    "xx, yy = mgrid[-2:2:.01, -2:2:.01]\n",
    "grid_arr = c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "def plot_decision(predicts):\n",
    "    probas = predicts.reshape(xx.shape)\n",
    "\n",
    "    contour = contourf(xx, yy, probas, 25, cmap=\"RdBu\", vmin=0, vmax=1)\n",
    "    colorbar(contour)\n",
    "\n",
    "    scatter(x[:,0], x[:, 1], c=y, s=50,\n",
    "                cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "                edgecolor=\"white\", linewidth=1)\n",
    "    title(\"Some cool decision boundary\")\n",
    "    grid()\n",
    "    \n",
    "scatter(x[:,0], x[:, 1], c=y, s=75,\n",
    "            cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "            edgecolor=\"white\", linewidth=1)\n",
    "title(\"Toy data\")\n",
    "grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# allocate parameters\n",
    "W = theano.shared(\n",
    "    value=numpy.zeros((2, 1),dtype=theano.config.floatX), \n",
    "    name='W',  \n",
    "    borrow=True)\n",
    "\n",
    "b = theano.shared(\n",
    "    value=numpy.zeros((1,), dtype=theano.config.floatX),\n",
    "    name='b',\n",
    "    borrow=True)\n",
    "\n",
    "# and define symbolic variables\n",
    "X = T.matrix('X')\n",
    "Y = T.imatrix('Y')\n",
    "\n",
    "# define model\n",
    "linear = T.dot(X, W) + b\n",
    "p_y_given_x = T.nnet.sigmoid(linear)\n",
    "y_pred = p_y_given_x > 0.5\n",
    "\n",
    "# define loss-function\n",
    "loss = T.nnet.binary_crossentropy(p_y_given_x, Y).mean()\n",
    "\n",
    "# compute the gradients\n",
    "g_W = T.grad(loss, W)\n",
    "g_b = T.grad(loss, b)\n",
    "\n",
    "# define parametes updates\n",
    "updates = [(W, W - 0.04 * g_W),\n",
    "           (b, b - 0.08 * g_b)]\n",
    "\n",
    "# compile functions\n",
    "train = theano.function(\n",
    "    inputs=[X, Y],\n",
    "    outputs=loss,\n",
    "    updates=updates,\n",
    "    allow_input_downcast=True\n",
    ")\n",
    "\n",
    "predict_proba = theano.function(\n",
    "    [X],\n",
    "    p_y_given_x,\n",
    "    allow_input_downcast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SGD is love SGD is life\n",
    "batch_size = 4\n",
    "\n",
    "for epoch_ in xrange(301):\n",
    "    loss = []\n",
    "    # iterate over training samples in minibatches\n",
    "    for iter_ in xrange(x.shape[0] // batch_size):\n",
    "        minibatch = slice(iter_ * batch_size, (iter_ + 1) * batch_size)\n",
    "        loss.append(train(x[minibatch], y[minibatch, np.newaxis]))\n",
    "    \n",
    "    e_loss = mean(loss)\n",
    "    if not epoch_ % 10:\n",
    "        print(\"[Epoch %03d] Train loss: %f\" % (epoch_, e_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probas = predict_proba(grid_arr)\n",
    "plot_decision(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "W = theano.shared(\n",
    "    value=numpy.zeros((2, 1),dtype=theano.config.floatX), \n",
    "    name='W',  \n",
    "    borrow=True)\n",
    "\n",
    "b = theano.shared(\n",
    "    value=numpy.zeros((1,), dtype=theano.config.floatX),\n",
    "    name='b',\n",
    "    borrow=True)\n",
    "\n",
    "# and define symbolic variables\n",
    "X = T.matrix('X')\n",
    "Y = T.imatrix('Y')\n",
    "\n",
    "# define model\n",
    "linear = T.dot(X, W) + b\n",
    "\n",
    "# We only need to change the loss function\n",
    "loss = T.maximum(0, 1 - linear * (Y * 2 - 1)).mean()\n",
    "\n",
    "# compute the gradients\n",
    "g_W = T.grad(loss, W)\n",
    "g_b = T.grad(loss, b)\n",
    "\n",
    "# define parametes updates\n",
    "updates = [(W, W - 0.04 * g_W),\n",
    "           (b, b - 0.08 * g_b)]\n",
    "\n",
    "# compile functions\n",
    "train = theano.function(\n",
    "    inputs=[X, Y],\n",
    "    outputs=[loss],\n",
    "    updates=updates,\n",
    "    allow_input_downcast=True\n",
    ")\n",
    "               \n",
    "predict = theano.function(\n",
    "    [X],\n",
    "    linear > 0,\n",
    "    allow_input_downcast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch_ in xrange(301):\n",
    "    loss = []\n",
    "    # iterate over training samples in minibatches\n",
    "    for iter_ in xrange(x.shape[0] // batch_size):\n",
    "        minibatch = slice(iter_ * batch_size, (iter_ + 1) * batch_size)\n",
    "        loss.append(train(x[minibatch], y[minibatch, np.newaxis]))\n",
    "    \n",
    "    e_loss = mean(loss)\n",
    "    if not epoch_ % 10:\n",
    "        print(\"[Epoch %03d] Train loss: %f\" % (epoch_, e_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = predict(grid_arr)\n",
    "plot_decision(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Kernel\" trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# meet theano's scan:\n",
    "# allocate variable\n",
    "i = T.lscalar(\"i\")\n",
    "\n",
    "# fn parameters: sequences (if any), prior result(s) (if needed), non-sequences (if any)\n",
    "# the sequences argument is ommited in this example\n",
    "result, updates = theano.scan(fn=lambda prior_result, i: prior_result * i,\n",
    "                              # initialize the output\n",
    "                              outputs_info=T.ones_like(i),\n",
    "                              # pass input as non sequence\n",
    "                              non_sequences=i,\n",
    "                              # this many iterations\n",
    "                              n_steps=3)\n",
    "\n",
    "# compile the function\n",
    "poly = theano.function(inputs=[i], \n",
    "                        outputs=result,\n",
    "                        updates=updates, # actually safe to omit in this case\n",
    "                        allow_input_downcast=True)\n",
    "poly(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# meet theano's scan 2:\n",
    "# allocate variable\n",
    "I = T.lmatrix(\"I\")\n",
    "\n",
    "# fn parameters: sequences (if any), prior result(s) (if needed), non-sequences (if any)\n",
    "# the sequences argument is ommited in this example\n",
    "result, updates = theano.scan(fn=lambda prior_result, I: prior_result * I,\n",
    "                              # initialize the output\n",
    "                              outputs_info=T.ones_like(I),\n",
    "                              # pass input as non sequence\n",
    "                              non_sequences=I,\n",
    "                              # this many iterations\n",
    "                              n_steps=2)\n",
    "\n",
    "# x  y  -> x  y  x^2  y^2\n",
    "# x' y' -> x' y' x'^2 y'^2\n",
    "\n",
    "output = result.dimshuffle(1, 0, 2).reshape((result.shape[1], \n",
    "                                             result.shape[0] * result.shape[2]))\n",
    "# compile the function\n",
    "poly = theano.function(inputs=[I], \n",
    "                        outputs=output,\n",
    "                        updates=updates, # actually safe to omit in this case\n",
    "                        allow_input_downcast=True)\n",
    "output = poly((arange(6) + 1).reshape(3, 2))\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More documentation on looping in Theano: http://deeplearning.net/software/theano/library/scan.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "def poly(inp, degree=2):\n",
    "  \n",
    "    result, updates = theano.scan(fn=lambda prior_result, inp: prior_result * inp,\n",
    "                                  # initialize the output\n",
    "                                  outputs_info=T.ones_like(inp),\n",
    "                                  # pass input as non sequence\n",
    "                                  non_sequences=inp,\n",
    "                                  # this many iterations\n",
    "                                  n_steps=degree)\n",
    "    return result.dimshuffle(1, 0, 2).reshape((result.shape[1], \n",
    "                                               result.shape[0] * result.shape[2]))\n",
    "\n",
    "# reset parameters\n",
    "W = theano.shared(\n",
    "    value=numpy.zeros((8, 1),dtype=theano.config.floatX), \n",
    "    name='W',  \n",
    "    borrow=True)\n",
    "\n",
    "b = theano.shared(\n",
    "    value=numpy.zeros((1,), dtype=theano.config.floatX),\n",
    "    name='b',\n",
    "    borrow=True)\n",
    "# and define symbolic variables\n",
    "X = T.matrix('X')\n",
    "Y = T.imatrix('Y')\n",
    "\n",
    "# define model\n",
    "linear = T.dot(poly(X, degree=2), W) + b\n",
    "\n",
    "# We only need to change the loss function\n",
    "loss = T.maximum(0, 1 - linear * (Y * 2 - 1)).mean()\n",
    "\n",
    "# compute the gradients\n",
    "g_W = T.grad(loss, W)\n",
    "g_b = T.grad(loss, b)\n",
    "\n",
    "# define parametes updates\n",
    "updates = [(W, W - 0.04 * g_W),\n",
    "           (b, b - 0.08 * g_b)]\n",
    "\n",
    "# compile functions\n",
    "train = theano.function(\n",
    "    inputs=[X, Y],\n",
    "    outputs=[loss],\n",
    "    updates=updates,\n",
    "    allow_input_downcast=True\n",
    ")\n",
    "               \n",
    "predict = theano.function(\n",
    "    [X],\n",
    "    linear > 0,\n",
    "    allow_input_downcast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "for epoch_ in xrange(301):\n",
    "    loss = []\n",
    "    # iterate over training samples in minibatches\n",
    "    for iter_ in xrange(x.shape[0] // batch_size):\n",
    "        minibatch = slice(iter_ * batch_size, (iter_ + 1) * batch_size)\n",
    "        loss.append(train(x[minibatch], y[minibatch, np.newaxis]))\n",
    "    \n",
    "    e_loss = mean(loss)\n",
    "    if not epoch_ % 10:\n",
    "        print(\"[Epoch %03d] Train loss: %f\" % (epoch_, e_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = predict(grid_arr)\n",
    "plot_decision(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset parameters\n",
    "W = theano.shared(\n",
    "    value=zeros((8, 1),dtype=theano.config.floatX), \n",
    "    name='W',  \n",
    "    borrow=True)\n",
    "\n",
    "b = theano.shared(\n",
    "    value=zeros((1,), dtype=theano.config.floatX),\n",
    "    name='b',\n",
    "    borrow=True)\n",
    "# and define symbolic variables\n",
    "X = T.matrix('X')\n",
    "Y = T.imatrix('Y')\n",
    "\n",
    "# define model\n",
    "linear = T.dot(poly(X, degree=4), W) + b\n",
    "\n",
    "# We only need to change the loss function\n",
    "loss = T.maximum(0, 1 - linear * (Y * 2 - 1)).mean() + 1e-3 * T.sum(W ** 2)\n",
    "\n",
    "# compute the gradients\n",
    "g_W = T.grad(loss, W)\n",
    "g_b = T.grad(loss, b)\n",
    "\n",
    "# define parametes updates\n",
    "updates = [(W, W - 0.04 * g_W),\n",
    "           (b, b - 0.08 * g_b)]\n",
    "\n",
    "# compile functions\n",
    "train = theano.function(\n",
    "    inputs=[X, Y],\n",
    "    outputs=loss,\n",
    "    updates=updates,\n",
    "    allow_input_downcast=True\n",
    ")\n",
    "               \n",
    "predict = theano.function(\n",
    "    inputs=[X],\n",
    "    linear > 0,\n",
    "    allow_input_downcast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "for epoch_ in xrange(301):\n",
    "    loss = []\n",
    "    # iterate over training samples in minibatches\n",
    "    for iter_ in xrange(x.shape[0] // batch_size):\n",
    "        minibatch = slice(iter_ * batch_size, (iter_ + 1) * batch_size)\n",
    "        loss.append(train(x[minibatch], y[minibatch, np.newaxis]))\n",
    "    \n",
    "    e_loss = mean(loss)\n",
    "    if not epoch_ % 10:\n",
    "        print(\"[Epoch %03d] Train loss: %f\" % (epoch_, e_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = predict(grid_arr)\n",
    "plot_decision(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasagne is a lightweight library to build and train neural networks in Theano:\n",
    "\n",
    "https://github.com/Lasagne/Lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.utils import floatX\n",
    "\n",
    "import gzip\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget -P data http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!wget -P data  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the following code has been mostly adopted from https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py\n",
    "# you are encouraged to go through the example there or have a look at a more in-depth tutorial: \n",
    "# http://lasagne.readthedocs.org/en/latest/user/tutorial.html\n",
    "\n",
    "def plot_mnist_sample(sample):\n",
    "    imshow(sample[0], cmap=cm.Greys_r)\n",
    "    xticks([])\n",
    "    yticks([])\n",
    "\n",
    "with gzip.open(\"data/train-images-idx3-ubyte.gz\", 'rb') as f:\n",
    "    X = frombuffer(f.read(), uint8, offset=16).reshape(-1, 1, 28, 28)\n",
    "    X = X / floatX(256)\n",
    "    \n",
    "with gzip.open(\"data/train-labels-idx1-ubyte.gz\", 'rb') as f:\n",
    "    y = frombuffer(f.read(), uint8, offset=8)\n",
    "    \n",
    "X_train, X_val = X[:-10000], X[-10000:]\n",
    "y_train, y_val = y[:-10000], y[-10000:]\n",
    "\n",
    "plot_mnist_sample(X_train[randint(0, 10000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(input_var=None):\n",
    "    # This creates an MLP of two hidden layers of 800 units each, followed by\n",
    "    # a softmax output layer of 10 units. It applies 20% dropout to the input\n",
    "    # data and 50% dropout to the hidden layers.\n",
    "\n",
    "    # Input layer, specifying the expected input shape of the network\n",
    "    # (unspecified batchsize, 1 channel, 28 rows and 28 columns) and\n",
    "    # linking it to the given Theano variable `input_var`, if any:\n",
    "    network = lasagne.layers.InputLayer(\n",
    "        shape=(None, 1, 28, 28),\n",
    "        input_var=input_var)\n",
    "    \n",
    "    # Apply 20% dropout to the input data:\n",
    "    network = lasagne.layers.DropoutLayer(network, p=0.2)\n",
    "\n",
    "    # Add a fully-connected layer of 800 units, using the linear rectifier, and\n",
    "    # initializing weights with Glorot's scheme (which is the default anyway):\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "        network, \n",
    "        num_units=800,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "\n",
    "    # We'll now add dropout of 50%:\n",
    "    network = lasagne.layers.DropoutLayer(network, p=0.5)\n",
    "\n",
    "    # Another 800-unit layer:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "        network,\n",
    "        num_units=800,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # 50% dropout again:\n",
    "    network = lasagne.layers.DropoutLayer(network, p=0.5)\n",
    "\n",
    "    # Finally, we'll add the fully-connected output layer, of 10 softmax units:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "        network,\n",
    "        num_units=10,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "def build_cnn(input_var=None):\n",
    "    # As a third model, we'll create a CNN of two convolution + pooling stages\n",
    "    # and a fully-connected hidden layer in front of the output layer.\n",
    "    \n",
    "    # Input layer, as usual:\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                        input_var=input_var)\n",
    "    # This time we do not apply input dropout, as it tends to work less well\n",
    "    # for convolutional layers.\n",
    "\n",
    "    # Convolutional layer with 32 kernels of size 5x5. Strided and padded\n",
    "    # convolutions are supported as well; see the docstring.\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "        network, \n",
    "        num_filters=32,\n",
    "        filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform())\n",
    "    \n",
    "    # Expert note: Lasagne provides alternative convolutional layers that\n",
    "    # override Theano's choice of which implementation to use; for details\n",
    "    # please see http://lasagne.readthedocs.org/en/latest/user/tutorial.html.\n",
    "\n",
    "    # Max-pooling layer of factor 2 in both dimensions:\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # Another convolution with 32 5x5 kernels, and another 2x2 pooling:\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "        network,\n",
    "        num_filters=32,\n",
    "        filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of 256 units with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=256,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = arange(len(inputs))\n",
    "        random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "# choose MLP or CNN\n",
    "network = build_mlp(input_var)\n",
    "#network = build_cnn(input_var)\n",
    "\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()\n",
    "# We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "# Create update expressions for training, i.e., how to modify the\n",
    "# parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "# Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "    loss, \n",
    "    params, \n",
    "    learning_rate=0.01, \n",
    "    momentum=0.9)\n",
    "\n",
    "# Create a loss expression for validation/testing. The crucial difference\n",
    "# here is that we do a deterministic forward pass through the network,\n",
    "# disabling dropout layers.\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = T.nnet.categorical_crossentropy(test_prediction,\n",
    "                                                        target_var)\n",
    "test_loss = test_loss.mean()\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "test_acc = T.mean(\n",
    "    T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "    dtype=theano.config.floatX)\n",
    "\n",
    "train = theano.function(\n",
    "    inputs=[input_var, target_var],\n",
    "    outputs=loss,\n",
    "    updates=updates)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "validate = theano.function(\n",
    "    inputs=[input_var, target_var],\n",
    "    outputs=[test_loss, test_acc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"| Epoch | Train err | Validation err | Accuracy |  Time  |\")\n",
    "print(\"|--------------------------------------------------------|\")\n",
    "\n",
    "try:\n",
    "    for epoch in xrange(500):\n",
    "            # In each epoch, we do a full pass over the training data:\n",
    "            train_err = 0\n",
    "            train_batches = 0\n",
    "            start_time = time.time()\n",
    "            for batch in iterate_minibatches(X_train, y_train, 500, shuffle=True):\n",
    "                inputs, targets = batch\n",
    "                train_err += train(inputs, targets)\n",
    "                train_batches += 1\n",
    "\n",
    "            # And a full pass over the validation data:\n",
    "            val_err = 0\n",
    "            val_acc = 0\n",
    "            val_batches = 0\n",
    "            for batch in iterate_minibatches(X_val, y_val, 500, shuffle=False):\n",
    "                inputs, targets = batch\n",
    "                err, acc = validate(inputs, targets)\n",
    "                val_err += err\n",
    "                val_acc += acc\n",
    "                val_batches += 1\n",
    "\n",
    "            print(\"|%6d | %9.6f | %14.6f | %8.2f | %6d |\" %\n",
    "                            (epoch,\n",
    "                             train_err / train_batches,\n",
    "                             val_err / val_batches,\n",
    "                             val_acc / val_batches * 100,\n",
    "                             time.time() - start_time))\n",
    "except KeyboardInterrupt:\n",
    "    print(\"The training was interrupted on epoch: %d.\" % epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the weights\n",
    "savez('model.npz', *lasagne.layers.get_all_param_values(network))\n",
    "\n",
    "network = build_mlp()\n",
    "# And load them again later on like this:\n",
    "with np.load('model.npz') as f:\n",
    "     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "lasagne.layers.set_all_param_values(network, param_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting predictions out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build the expression\n",
    "predictions = T.argmax(test_prediction, axis=1)\n",
    "\n",
    "# define the prediction function\n",
    "predict = theano.function(\n",
    "    inputs=[input_var],\n",
    "    outputs=predictions)\n",
    "\n",
    "# get just one batch for simplicity\n",
    "inputs, targets = iterate_minibatches(X_val, y_val, 500, shuffle=False).next()\n",
    "preds = predict(inputs)\n",
    "bad_samples = where(preds != targets)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = random.choice(bad_samples)\n",
    "plot_mnist_sample(X_val[error])\n",
    "print(\"Predicted: %d True: %d\" % (preds[error], targets[error]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of interesting stuff here: https://github.com/Lasagne/Recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you for your attention!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
